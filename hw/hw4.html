<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.242">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Shao-Ting Chiu (UIN:433002162)">
<meta name="dcterms.date" content="2023-01-20">

<title>STAT638: Applied Bayesian Methods - 8&nbsp; Homework 4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../hw/hw5.html" rel="next">
<link href="../hw/hw3.html" rel="prev">
<link href="../img/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">STAT638: Applied Bayesian Methods</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/stevengogogo/STAT638_Applied-Bayes-Methods"><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
                  <a href="" class="quarto-reader-toggle nav-link" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Homework 4</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true"><strong>Lecture Notes</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ch1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Chapter 1 Introduction and examples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ch2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Chapter 2: Conditional distributions and Bayes rule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ch3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 3: One-parameter models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ch4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 4: Monte Carlo Approximation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true"><strong>Assignments</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Homework 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Homework 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Homework 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw4.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Homework 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework 5</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw6.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Homework 6</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw7.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Homework 7</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw8.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Homework 8</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw9.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Homework 9</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hw/hw10.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Homework 10</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ref.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#description" id="toc-description" class="nav-link active" data-scroll-target="#description"><span class="toc-section-number">8.1</span>  Description</a></li>
  <li><a href="#computational-enviromnent-setup" id="toc-computational-enviromnent-setup" class="nav-link" data-scroll-target="#computational-enviromnent-setup"><span class="toc-section-number">8.2</span>  Computational Enviromnent Setup</a>
  <ul class="collapse">
  <li><a href="#third-party-libraries" id="toc-third-party-libraries" class="nav-link" data-scroll-target="#third-party-libraries"><span class="toc-section-number">8.2.1</span>  Third-party libraries</a></li>
  <li><a href="#version" id="toc-version" class="nav-link" data-scroll-target="#version"><span class="toc-section-number">8.2.2</span>  Version</a></li>
  </ul></li>
  <li><a href="#problem-4.1" id="toc-problem-4.1" class="nav-link" data-scroll-target="#problem-4.1"><span class="toc-section-number">8.3</span>  Problem 4.1</a></li>
  <li><a href="#problem-4.2" id="toc-problem-4.2" class="nav-link" data-scroll-target="#problem-4.2"><span class="toc-section-number">8.4</span>  Problem 4.2</a>
  <ul class="collapse">
  <li><a href="#a" id="toc-a" class="nav-link" data-scroll-target="#a"><span class="toc-section-number">8.4.1</span>  (a)</a></li>
  <li><a href="#b" id="toc-b" class="nav-link" data-scroll-target="#b"><span class="toc-section-number">8.4.2</span>  (b)</a></li>
  <li><a href="#c" id="toc-c" class="nav-link" data-scroll-target="#c"><span class="toc-section-number">8.4.3</span>  (c)</a></li>
  </ul></li>
  <li><a href="#problem-4.6" id="toc-problem-4.6" class="nav-link" data-scroll-target="#problem-4.6"><span class="toc-section-number">8.5</span>  Problem 4.6</a></li>
  <li><a href="#sec-p48" id="toc-sec-p48" class="nav-link" data-scroll-target="#sec-p48"><span class="toc-section-number">8.6</span>  Problem 4.8</a>
  <ul class="collapse">
  <li><a href="#a-1" id="toc-a-1" class="nav-link" data-scroll-target="#a-1"><span class="toc-section-number">8.6.1</span>  (a)</a></li>
  <li><a href="#b-1" id="toc-b-1" class="nav-link" data-scroll-target="#b-1"><span class="toc-section-number">8.6.2</span>  (b)</a></li>
  <li><a href="#c-1" id="toc-c-1" class="nav-link" data-scroll-target="#c-1"><span class="toc-section-number">8.6.3</span>  (c)</a></li>
  <li><a href="#d" id="toc-d" class="nav-link" data-scroll-target="#d"><span class="toc-section-number">8.6.4</span>  (d)</a></li>
  </ul></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix"><span class="toc-section-number">8.7</span>  Appendix</a>
  <ul class="collapse">
  <li><a href="#sec-data" id="toc-sec-data" class="nav-link" data-scroll-target="#sec-data"><span class="toc-section-number">8.7.1</span>  Data set in Problem 4.8</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Homework 4</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading"></div>
  
    <div class="quarto-title-meta-contents">
    <a href="stchiu@email.tamu.edu">Shao-Ting Chiu (UIN:433002162)</a> 
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Department of Electrical and Computer Engineering, Texas A&amp;M University
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 20, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="description" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="description"><span class="header-section-number">8.1</span> Description</h2>
<ul>
<li>Course: STAT638, 2022 Fall</li>
</ul>
<blockquote class="blockquote">
<p>Read Chapter 4 in Hoff.</p>
<p>Then, do the following exercises in Hoff: 4.1, 4.2, 4.6, 4.8</p>
<p>All datasets in the Hoff book can be downloaded from https://pdhoff.github.io/book/ (Links to an external site.).</p>
</blockquote>
<ul>
<li>Deadline: <code>Oct 4 by 12:01pm</code></li>
</ul>
<hr>
</section>
<section id="computational-enviromnent-setup" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="computational-enviromnent-setup"><span class="header-section-number">8.2</span> Computational Enviromnent Setup</h2>
<section id="third-party-libraries" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="third-party-libraries"><span class="header-section-number">8.2.1</span> Third-party libraries</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys <span class="co"># system information</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="co"># plotting</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy <span class="co"># scientific computing</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd <span class="co"># data managing</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> comb</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats <span class="im">as</span> st</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> gamma</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Matplotlib setting</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'text.usetex'</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>matplotlib.rcParams[<span class="st">'figure.dpi'</span>]<span class="op">=</span> <span class="dv">300</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">20220928</span>) <span class="co"># Consistent random effect</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="version" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="version"><span class="header-section-number">8.2.2</span> Version</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sys.version)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(matplotlib.__version__)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scipy.__version__)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.__version__)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.__version__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.9.12 (main, Apr  5 2022, 01:52:34) 
[Clang 12.0.0 ]
3.6.2
1.9.3
1.23.4
1.5.1</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="problem-4.1" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="problem-4.1"><span class="header-section-number">8.3</span> Problem 4.1</h2>
<blockquote class="blockquote">
<p>Posterior comparisons: Reconsider the sample survey in Exercise 3.1. Suppose you are interested in comparing the rate of support in that county to the rate in another county. Suppose that a survey of sample size <span class="math inline">\(50\)</span> was done in the second county, and the total number of people in the sample who supported the policy was <span class="math inline">\(30\)</span>. Identify the posterior distribution of <span class="math inline">\(\theta_2\)</span> assuming a uniform prior. Sample <span class="math inline">\(5000\)</span> values of each of <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> from their posterior distributions and estimate <span class="math inline">\(Pr(\theta_1 &lt; \theta_2|\text{ the data and prior })\)</span>.</p>
</blockquote>
<ul>
<li>Prior:
<ul>
<li><span class="math inline">\(\theta \sim beta(1,1)\)</span></li>
</ul></li>
<li>Model:
<ul>
<li><span class="math inline">\(p(\sum Y =n | \theta) = {N \choose n}\theta^{n}(1-\theta)^{N-n}\)</span></li>
</ul></li>
<li>Posterior distribution <span class="citation" data-cites="hoff2009first">(<a href="../ref.html#ref-hoff2009first" role="doc-biblioref">Hoff 2009, 580:37</a>)</span>:
<ul>
<li><span class="math inline">\(\theta | \sum_{i=1}^{N} Y_i=n \sim Beta(beta(1+n, 1+N-n))\)</span>
<ul>
<li><span class="math inline">\(\theta_1 \sim Beta(1+57, 1+100-57) = Beta(58, 44)\)</span></li>
<li><span class="math inline">\(\theta_2 \sim Beta(1+30, 1+50-30) = Beta(31, 21)\)</span></li>
</ul></li>
</ul></li>
</ul>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>t1s <span class="op">=</span> st.beta.rvs(<span class="dv">58</span>, <span class="dv">44</span>, size<span class="op">=</span>N)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>t2s <span class="op">=</span> st.beta.rvs(<span class="dv">31</span>, <span class="dv">21</span>, size<span class="op">=</span>N)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>p_t2bigger <span class="op">=</span> np.mean(t1s <span class="op">&lt;</span> t2s) </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Item"</span>: [<span class="st">"Pr(theta_1 &lt; theta_2 | the data and prior)"</span>],<span class="op">\</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value"</span>:[p_t2bigger]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Item</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Pr(theta_1 &lt; theta_2 | the data and prior)</td>
      <td>0.6292</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="problem-4.2" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="problem-4.2"><span class="header-section-number">8.4</span> Problem 4.2</h2>
<blockquote class="blockquote">
<p>Tumor count comparisons: Reconsider the tumor count data in <a href="hw2.pdf#sec-p-3-3">Exercise 3.3</a>:</p>
</blockquote>
<section id="a" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="a"><span class="header-section-number">8.4.1</span> (a)</h3>
<blockquote class="blockquote">
<p>For the prior distribution given in part (a) of that exercise, obtain <span class="math inline">\(Pr(\theta_B &lt; \theta_A | y_A, y_B)\)</span> via Monte Carlo sampling.</p>
</blockquote>
<ul>
<li>Prior distribution
<ul>
<li><span class="math inline">\(\theta_A|y_A \sim gamma(120+117, 10+10) = gamma(237, 20)\)</span></li>
<li><span class="math inline">\(\theta_B|y_B \sim gamma(12+113, 1+13) = gamma(125, 14)\)</span></li>
</ul></li>
</ul>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>theta_A <span class="op">=</span> st.gamma.rvs(<span class="dv">237</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">20</span>, size<span class="op">=</span>N)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>theta_B <span class="op">=</span> st.gamma.rvs(<span class="dv">125</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">14</span>, size<span class="op">=</span>N)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> np.mean(theta_B <span class="op">&lt;</span> theta_A)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Item"</span>: [<span class="st">"Pr(theta_B &lt; theta_A | y_A, y_B)"</span>],<span class="op">\</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value"</span>:[res]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Item</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Pr(theta_B &lt; theta_A | y_A, y_B)</td>
      <td>0.995</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="b" class="level3" data-number="8.4.2">
<h3 data-number="8.4.2" class="anchored" data-anchor-id="b"><span class="header-section-number">8.4.2</span> (b)</h3>
<blockquote class="blockquote">
<p>For a range of values of <span class="math inline">\(n_0\)</span>, obtain <span class="math inline">\(Pr(\theta_B &lt; \theta_A |y_A, y_B)\)</span> for <span class="math inline">\(\theta_A \sim gamma(120,10)\)</span> and <span class="math inline">\(\theta_B \sim gamma(12\times n_0, n_0)\)</span>. Describe how sensitive the conclusions about the event <span class="math inline">\(\{\theta_B &lt; \theta_A\}\)</span> are to the prior distribution on <span class="math inline">\(\theta_B\)</span>.</p>
</blockquote>
<p>In <a href="#fig-42-n0">Figure&nbsp;<span>8.1</span></a>, the <span class="math inline">\(n_0\)</span> decreases the probability of <span class="math inline">\(p(\{\theta_B &lt; \theta_A\})\)</span> with linear effect. From small to large <span class="math inline">\(n_0\)</span>, the prior distribution of <span class="math inline">\(\theta_B\)</span> keep influences the result.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_A_bigger(n0, N<span class="op">=</span><span class="dv">5000</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  theta_A <span class="op">=</span> st.gamma.rvs(<span class="dv">120</span> <span class="op">+</span> <span class="dv">117</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">10</span><span class="op">+</span><span class="dv">10</span>), size<span class="op">=</span>N)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  theta_B <span class="op">=</span> st.gamma.rvs(<span class="dv">12</span><span class="op">*</span>n0<span class="op">+</span><span class="dv">113</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(n0<span class="op">+</span><span class="dv">13</span>), size<span class="op">=</span>N)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  res <span class="op">=</span> np.mean(theta_B <span class="op">&lt;</span> theta_A)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> res</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>n0s <span class="op">=</span> np.arange(<span class="dv">1</span>,<span class="dv">50</span>, <span class="dv">1</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>ress <span class="op">=</span> [get_A_bigger(n0) <span class="cf">for</span> n0 <span class="kw">in</span> n0s]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>ax.plot(n0s, ress, <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$n_0$"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$p(</span><span class="ch">\\</span><span class="st">theta_B &lt; </span><span class="ch">\\</span><span class="st">theta_A | y_A, y_B, n_0)$"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-42-n0" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="hw4_files/figure-html/fig-42-n0-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;8.1: The effect of n0</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="c" class="level3" data-number="8.4.3">
<h3 data-number="8.4.3" class="anchored" data-anchor-id="c"><span class="header-section-number">8.4.3</span> (c)</h3>
<blockquote class="blockquote">
<p>Repeat part (a) and (b), replacing the event <span class="math inline">\(\{\theta_B &lt; \theta_A\}\)</span> with the event <span class="math inline">\(\{\tilde{Y}_{B} &lt; \tilde{Y}_{A}\}\)</span>, where <span class="math inline">\(\tilde{Y}_A\)</span> and <span class="math inline">\(\tilde{Y}_B\)</span> are samples from the posterior predictive distribution.</p>
</blockquote>
<p><strong>Part I (a)</strong></p>
<ul>
<li><p><span class="math inline">\(\tilde{Y}_A \sim nbinom(a+\sum Y^{(A)}, b + n) = nbinom(120+117,10+10)= nbinom(237, 20)\)</span></p></li>
<li><p><span class="math inline">\(\tilde{Y}_B \sim nbinom(a+\sum Y^{(B)}, b + n) = nbinom(12+113, 1+13) = nbinom(125, 14)\)</span></p></li>
<li><p>Find <span class="math inline">\(p(\tilde{Y}_{B} &lt; \tilde{Y}_A | y_A, y_B)\)</span></p></li>
<li><p>Use <code>scipy.stats.nbinom</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<ul>
<li><span class="math inline">\(p = 1 - \frac{1}{b+n+1}\)</span></li>
<li><span class="math inline">\(n = a+\sum Y\)</span></li>
<li><span class="math inline">\(k = \tilde{Y}\)</span></li>
</ul></li>
</ul>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>tilde_y_A <span class="op">=</span> st.nbinom.rvs(<span class="dv">120</span><span class="op">+</span><span class="dv">117</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">10</span><span class="op">+</span><span class="dv">10</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>tilde_y_B <span class="op">=</span> st.nbinom.rvs(<span class="dv">12</span><span class="op">+</span><span class="dv">113</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="dv">13</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>p2 <span class="op">=</span> np.mean(tilde_y_B <span class="op">&lt;</span> tilde_y_A)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Item"</span>: [<span class="st">"Pr(tildeY_B &lt; tildeY_A | y_A, y_B)"</span>],<span class="op">\</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value"</span>:[p2]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Item</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Pr(tildeY_B &lt; tildeY_A | y_A, y_B)</td>
      <td>0.6934</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p><strong>Part II (b)</strong></p>
<p>In <a href="#fig-423">Figure&nbsp;<span>8.2</span></a>, the <span class="math inline">\(n_0\)</span> has nonlinear negative effect on the probability <span class="math inline">\(p(\{\tilde{Y}_{B} &lt; \tilde{Y}_{A}\})\)</span> with the prior formation of <span class="math inline">\(n_0\)</span>.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_A_bigger(n0, N<span class="op">=</span><span class="dv">5000</span>):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  tilde_y_A <span class="op">=</span> st.nbinom.rvs(<span class="dv">120</span><span class="op">+</span><span class="dv">117</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">10</span><span class="op">+</span><span class="dv">10</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  tilde_y_B <span class="op">=</span> st.nbinom.rvs(<span class="dv">12</span><span class="op">*</span>n0<span class="op">+</span><span class="dv">113</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(n0<span class="op">+</span><span class="dv">13</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  res <span class="op">=</span> np.mean(tilde_y_B <span class="op">&lt;</span> tilde_y_A)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> res</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>n0s <span class="op">=</span> np.arange(<span class="dv">1</span>,<span class="dv">50</span>, <span class="dv">1</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>ress <span class="op">=</span> [get_A_bigger(n0) <span class="cf">for</span> n0 <span class="kw">in</span> n0s]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>ax.plot(n0s, ress, <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$n_0$"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$p(</span><span class="ch">\\</span><span class="st">tilde</span><span class="sc">{Y}</span><span class="st">_B &lt; </span><span class="ch">\\</span><span class="st">tilde</span><span class="sc">{Y}</span><span class="st">_A | y_A, y_B, n_0)$"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-423" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="hw4_files/figure-html/fig-423-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;8.2: The effect of n0</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="problem-4.6" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="problem-4.6"><span class="header-section-number">8.5</span> Problem 4.6</h2>
<blockquote class="blockquote">
<p>Non-informative prior distributions: Suppose for a binary sampling problem we plan on using a uniform, or <span class="math inline">\(beta(1,1)\)</span>, prior for the population proportion <span class="math inline">\(\theta\)</span>. Perhaps our reasoning is that this represents “no prior information about <span class="math inline">\(\theta\)</span>.” However, some people like to look at proportions on the log-odds scale, that is, they are interested in <span class="math inline">\(\gamma = \log\frac{\theta}{1−\theta}\)</span>. Via Monte Carlo sampling or otherwise, find the prior distribution for <span class="math inline">\(\gamma\)</span> that is induced by the uniform prior for <span class="math inline">\(\theta\)</span>. Is the prior informative about <span class="math inline">\(\gamma\)</span>?</p>
</blockquote>
<p><strong>Part I: Analytical Approach</strong></p>
<ul>
<li><span class="math inline">\(\gamma = g(\theta) = \log\frac{\theta}{1-\theta}\)</span></li>
<li><span class="math inline">\(\theta = g^{-1}(\gamma) = \frac{e^{\gamma}}{1+e^{\gamma}}\)</span></li>
</ul>
<p><span class="math display">\[\begin{align}
p_{\gamma}(\gamma)
&amp;= \underbrace{p_{\theta}(g^{-1}(\gamma))}_{=1 \because \theta\sim uniform(0,1)} \times \left|\frac{dg^{-1}(\gamma)}{d\gamma}\right|\\
&amp;= \left|\frac{e^{\gamma}}{(1+e^{\gamma})^2}\right|
\end{align}\]</span></p>
<p><strong>Part II: Monte Carlo Approach</strong></p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> true_gamma_pdf(y):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.absolute(np.exp(y)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(y))<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>ths <span class="op">=</span> st.beta.rvs(<span class="dv">1</span>,<span class="dv">1</span>,size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>gammas <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">100</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>ys_true <span class="op">=</span> [true_gamma_pdf(g) <span class="cf">for</span> g <span class="kw">in</span> gammas]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> [np.log(th<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>th)) <span class="cf">for</span> th <span class="kw">in</span> ths]</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()<span class="op">;</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>ax.hist(ys, weights<span class="op">=</span>np.ones_like(ys)<span class="op">/</span><span class="bu">len</span>(ys))<span class="op">;</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>ax.plot(gammas, ys_true, label<span class="op">=</span><span class="st">"Analytical solution"</span>)<span class="op">;</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">gamma=</span><span class="ch">\\</span><span class="st">log</span><span class="ch">\\</span><span class="st">frac{</span><span class="ch">\\</span><span class="st">theta}{1-</span><span class="ch">\\</span><span class="st">theta}$"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$p(</span><span class="ch">\\</span><span class="st">gamma)$"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="hw4_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>The prior of <span class="math inline">\(\gamma\)</span> is informative since it is centered around the <span class="math inline">\(0\)</span>.</li>
</ul>
</section>
<section id="sec-p48" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="sec-p48"><span class="header-section-number">8.6</span> Problem 4.8</h2>
<blockquote class="blockquote">
<p>More posterior predictive checks: Let <span class="math inline">\(\theta_A\)</span> and <span class="math inline">\(\theta_B\)</span> be the average number of children of men in their 30s with and without bachelor’s degrees, respectively.</p>
</blockquote>
<section id="a-1" class="level3" data-number="8.6.1">
<h3 data-number="8.6.1" class="anchored" data-anchor-id="a-1"><span class="header-section-number">8.6.1</span> (a)</h3>
<blockquote class="blockquote">
<p>Using a Poisson sampling model, a <span class="math inline">\(gamma(2,1)\)</span> prior for each <span class="math inline">\(\theta\)</span> and the data in the files <a href="data/menchild30bach.dat.txt"><code>menchild30bach.dat</code></a> and <a href="data/menchild30nobach.dat.txt"><code>menchild30nobach.dat</code></a>, obtain <span class="math inline">\(5000\)</span> samples of <span class="math inline">\(\bar{Y}_{A}\)</span> and <span class="math inline">\(\bar{Y}_{B}\)</span> from the posterior predictive distribution of the two samples. Plot the Monte Carlo approximations to these two posterior predictive distributions. (data available in <a href="#sec-data">Appendix</a>)</p>
</blockquote>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>dataA <span class="op">=</span> np.loadtxt(<span class="st">"data/menchild30bach.dat"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>dataB <span class="op">=</span> np.loadtxt(<span class="st">"data/menchild30nobach.dat"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display </span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Properties"</span>: [<span class="st">"Sum"</span>, <span class="st">"N (number of samples)"</span>],</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"A"</span>: [np.<span class="bu">sum</span>(dataA), <span class="bu">len</span>(dataA)],</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"B"</span>: [np.<span class="bu">sum</span>(dataB), <span class="bu">len</span>(dataB)]</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Properties</th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Sum</td>
      <td>54.0</td>
      <td>305.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>N (number of samples)</td>
      <td>58.0</td>
      <td>218.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>The predictive distribution is</p>
<ul>
<li><span class="math inline">\(\bar{Y_A} | y_A \sim nbinom(2+54,1+58)\)</span></li>
<li><span class="math inline">\(\bar{Y_B} | y_B \sim nbinom(2+305, 1+218)\)</span></li>
</ul>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>bar_ya <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span> np.<span class="bu">sum</span>(dataA), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataA)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>bar_yb <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span> np.<span class="bu">sum</span>(dataB), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataB)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()<span class="op">;</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>[ax.hist(ys, weights<span class="op">=</span>np.ones_like(ys)<span class="op">/</span><span class="bu">len</span>(ys), label<span class="op">=</span>n, alpha<span class="op">=</span><span class="fl">0.7</span>, bins<span class="op">=</span>np.arange(<span class="dv">0</span>,<span class="dv">8</span>,<span class="dv">1</span>)) <span class="cf">for</span> n,ys <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">"A"</span>,<span class="st">"B"</span>],[bar_ya, bar_yb])]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$N$"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Probability"</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="hw4_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="b-1" class="level3" data-number="8.6.2">
<h3 data-number="8.6.2" class="anchored" data-anchor-id="b-1"><span class="header-section-number">8.6.2</span> (b)</h3>
<blockquote class="blockquote">
<p>Find <span class="math inline">\(95\%\)</span> quantile-based posterior confidence intervals for <span class="math inline">\(\theta_B - \theta_A\)</span> and <span class="math inline">\(\tilde{Y}_B-\tilde{Y}_A\)</span>. Describe in words the differences between the two populations using these quantities and the plots in (a), along with any other results that may of interest to you.</p>
</blockquote>
<ul>
<li><p><span class="math inline">\(\theta_A | y_A \sim gamma(2+54, 1+58)\)</span></p></li>
<li><p><span class="math inline">\(\theta_B | y_B \sim gamma(2+58, 1+218)\)</span></p></li>
<li><p><span class="math inline">\(\bar{Y_A} | y_A \sim nbinom(2+54,1+58)\)</span></p></li>
<li><p><span class="math inline">\(\bar{Y_B} | y_B \sim nbinom(2+305, 1+218)\)</span></p></li>
<li><p>The <span class="math inline">\(95\%\)</span> confidence interval does not contain the negative region. Thus, the belief of <span class="math inline">\(\theta_B &gt; \theta_A\)</span> is confident.</p></li>
<li><p>However, there is more uncertainty about the posterior predictive distribution, leading to the uncertain quantity comparison between <span class="math inline">\(Y_A\)</span> and <span class="math inline">\(Y_B\)</span>.</p></li>
</ul>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>thetaAs <span class="op">=</span> st.gamma.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataA), scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataA)), size<span class="op">=</span>N)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>thetaBs <span class="op">=</span> st.gamma.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataB), scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataB)), size<span class="op">=</span>N)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>YAs <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataA), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataA)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>YBs <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataB), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataB)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>theta_diff <span class="op">=</span> thetaBs <span class="op">-</span> thetaAs</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>Y_diff <span class="op">=</span> YBs <span class="op">-</span> YAs</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>theta_quan <span class="op">=</span> st.mstats.mquantiles(theta_diff, prob<span class="op">=</span>[<span class="fl">0.025</span>, <span class="fl">0.975</span>])</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>Y_quan <span class="op">=</span> st.mstats.mquantiles(Y_diff, prob<span class="op">=</span>[<span class="fl">0.025</span>, <span class="fl">0.975</span>])</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"RVs"</span>:[<span class="st">"Interval (thetaB-thetaA)"</span>, <span class="st">"Interval (YB-YA)"</span>],<span class="op">\</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value (2.5%; 97.5%)"</span>:[theta_quan, Y_quan]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>RVs</th>
      <th>Value (2.5%; 97.5%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Interval (thetaB-thetaA)</td>
      <td>[0.14120795305853456, 0.7436235075695707]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Interval (YB-YA)</td>
      <td>[-3.0, 4.0]</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plt.hist(theta_diff, weights<span class="op">=</span>np.ones_like(theta_diff)<span class="op">/</span><span class="bu">len</span>(theta_diff), alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribution of ThetaB - ThetaA"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="hw4_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>plt.hist(Y_diff, weights<span class="op">=</span>np.ones_like(Y_diff)<span class="op">/</span><span class="bu">len</span>(Y_diff), alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribution of YB - YA"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="hw4_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="c-1" class="level3" data-number="8.6.3">
<h3 data-number="8.6.3" class="anchored" data-anchor-id="c-1"><span class="header-section-number">8.6.3</span> (c)</h3>
<blockquote class="blockquote">
<p>Obtain the empirical distribution of the data in group <span class="math inline">\(B\)</span>. Compare this to the Poisson distribution with mean <span class="math inline">\(\hat{\theta}=1.4\)</span>. Do you think the Poisson model is a good fit? Why or Why not?</p>
</blockquote>
<ul>
<li><span class="math inline">\(\bar{Y}_B | y_B \sim nbinom(307, 219)\)</span></li>
<li>The poisson model is not a good fit to the group <span class="math inline">\(B\)</span>. As shown in the historgram, there are more than one peak in the distribution, that is not the characteristic of Poisson distribution.</li>
</ul>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.arange(<span class="dv">0</span>,<span class="dv">7</span>,<span class="dv">1</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>ps <span class="op">=</span> [st.poisson.pmf(x, <span class="fl">1.4</span>) <span class="cf">for</span> x <span class="kw">in</span> xs]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>ax.hist(dataB, weights<span class="op">=</span>np.ones_like(dataB)<span class="op">/</span><span class="bu">len</span>(dataB), alpha<span class="op">=</span><span class="fl">0.7</span>)<span class="op">;</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>ax.plot(xs, ps, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Poisson($</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">theta}$=1.4)"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="hw4_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="d" class="level3" data-number="8.6.4">
<h3 data-number="8.6.4" class="anchored" data-anchor-id="d"><span class="header-section-number">8.6.4</span> (d)</h3>
<blockquote class="blockquote">
<p>For each of the <span class="math inline">\(5000\)</span> <span class="math inline">\(\theta_B\)</span>-valeus you sampled, sample <span class="math inline">\(n_B=218\)</span> Poisson random variables and count the number of <span class="math inline">\(0\)</span>s and the number of <span class="math inline">\(1\)</span>s in each of the <span class="math inline">\(5000\)</span> simulated datasets. You should now have tow sequences of length <span class="math inline">\(5000\)</span> each, one sequence counting the number of people having zero children for each of the <span class="math inline">\(5000\)</span> posterior predictive datasets, the other counting the number of people with one child. Plot the two sequences against one another (one on the <span class="math inline">\(x\)</span>-axis, one on the <span class="math inline">\(y\)</span>-axis). Add to the plot a point marking how many people in the observed dataset had zero children and one child. Using this plot, describe the adequency of the Poisson model.</p>
</blockquote>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>thetaBs <span class="op">=</span> thetaBs</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>nB <span class="op">=</span> <span class="dv">218</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>ybs0 <span class="op">=</span> np.zeros(<span class="bu">len</span>(thetaBs))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>ybs1 <span class="op">=</span> np.zeros(<span class="bu">len</span>(thetaBs))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i, th) <span class="kw">in</span> <span class="bu">enumerate</span>(thetaBs):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  seq <span class="op">=</span> st.poisson.rvs(th, size<span class="op">=</span>nB)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  ybs0[i] <span class="op">=</span> <span class="bu">len</span>(seq[seq<span class="op">==</span><span class="dv">0</span>])</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  ybs1[i] <span class="op">=</span> <span class="bu">len</span>(seq[seq<span class="op">==</span><span class="dv">1</span>])</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>ax.plot(ybs0, ybs1, <span class="st">"o"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">len</span>(dataB[dataB<span class="op">==</span><span class="dv">0</span>]), <span class="bu">len</span>(dataB[dataB<span class="op">==</span><span class="dv">1</span>]), <span class="st">'o'</span>,color<span class="op">=</span><span class="st">"r"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"N of people with zero children"</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"N of people with one children"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>Text(0, 0.5, 'N of people with one children')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="hw4_files/figure-html/cell-16-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>The observed data is in red, but the simulated data is centralized far from that point. Thus, the poisson model is not appropriate for this dataset.</li>
</ul>
</section>
</section>
<section id="appendix" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="appendix"><span class="header-section-number">8.7</span> Appendix</h2>
<section id="sec-data" class="level3" data-number="8.7.1">
<h3 data-number="8.7.1" class="anchored" data-anchor-id="sec-data"><span class="header-section-number">8.7.1</span> Data set in <a href="#sec-p48">Problem 4.8</a></h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"menchild30bach.dat:</span><span class="ch">\n</span><span class="st">"</span>, dataA)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"menchild30nobach.dat:</span><span class="ch">\n</span><span class="st">"</span>, dataB)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>menchild30bach.dat:
 [1. 0. 0. 1. 2. 2. 1. 5. 2. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 2.
 1. 3. 2. 0. 0. 3. 0. 0. 0. 2. 1. 0. 2. 1. 0. 0. 1. 3. 0. 1. 1. 0. 2. 0.
 0. 2. 2. 1. 3. 0. 0. 0. 1. 1.]
menchild30nobach.dat:
 [2. 2. 1. 1. 2. 2. 1. 2. 1. 0. 2. 1. 1. 2. 0. 2. 2. 0. 2. 1. 0. 0. 3. 6.
 1. 6. 4. 0. 3. 2. 0. 1. 0. 0. 0. 3. 0. 0. 0. 0. 0. 1. 0. 4. 2. 1. 0. 0.
 1. 0. 3. 2. 5. 0. 1. 1. 2. 1. 2. 1. 2. 0. 0. 0. 2. 1. 0. 2. 0. 2. 4. 1.
 1. 1. 2. 0. 1. 1. 1. 1. 0. 2. 3. 2. 0. 2. 1. 3. 1. 3. 2. 2. 3. 2. 0. 0.
 0. 1. 0. 0. 0. 1. 2. 0. 3. 3. 0. 1. 2. 2. 2. 0. 6. 0. 0. 0. 2. 0. 1. 1.
 1. 3. 3. 2. 1. 1. 0. 1. 0. 0. 2. 0. 2. 0. 1. 0. 2. 0. 0. 2. 2. 4. 1. 2.
 3. 2. 0. 0. 0. 1. 0. 0. 1. 5. 2. 1. 3. 2. 0. 2. 1. 1. 3. 0. 5. 0. 0. 2.
 4. 3. 4. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 2. 0. 0. 1. 1. 0. 2. 1. 3. 3. 2.
 2. 0. 0. 2. 3. 2. 4. 3. 3. 4. 0. 3. 0. 1. 0. 1. 2. 3. 4. 1. 2. 6. 2. 1.
 2. 2.]</code></pre>
</div>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-hoff2009first" class="csl-entry" role="doc-biblioentry">
Hoff, Peter D. 2009. <em>A First Course in Bayesian Statistical Methods</em>. Vol. 580. Springer.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.nbinom.html#scipy.stats.nbinom<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../hw/hw3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Homework 3</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../hw/hw5.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework 5</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb20" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Homework 4</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> </span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Shao-Ting Chiu (UIN:433002162)</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">    url: stchiu@email.tamu.edu</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: Department of Electrical and Computer Engineering, Texas A\&amp;M University</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> today</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf:</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">    table-of-contents: true</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-line-numbers: true</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co">    table-of-contents: true</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> ../ref.bib</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3  </span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span><span class="co"> </span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co">    echo: true</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co">    freeze: auto</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## Description</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Course: STAT638, 2022 Fall</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Read Chapter 4 in Hoff.</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Then, do the following exercises in Hoff: 4.1, 4.2, 4.6, 4.8</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; All datasets in the Hoff book can be downloaded from https://pdhoff.github.io/book/ (Links to an external site.).</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Deadline: <span class="in">`Oct 4 by 12:01pm`</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="fu">## Computational Enviromnent Setup</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a><span class="fu">### Third-party libraries</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys <span class="co"># system information</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="co"># plotting</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy <span class="co"># scientific computing</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random </span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd <span class="co"># data managing</span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> comb</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats <span class="im">as</span> st</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> gamma</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Matplotlib setting</span></span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'text.usetex'</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>matplotlib.rcParams[<span class="st">'figure.dpi'</span>]<span class="op">=</span> <span class="dv">300</span></span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">20220928</span>) <span class="co"># Consistent random effect</span></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### Version</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sys.version)</span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(matplotlib.__version__)</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scipy.__version__)</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.__version__)</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.__version__)</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a><span class="fu">## Problem 4.1</span></span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Posterior comparisons: Reconsider the sample survey in Exercise 3.1. Suppose you are interested in comparing the rate of support in that county to the rate in another county. Suppose that a survey of sample size $50$ was done in the second county, and the total number of people in the sample who supported the policy was $30$. Identify the posterior distribution of $\theta_2$ assuming a uniform prior. Sample $5000$ values of each of $\theta_1$ and $\theta_2$ from their posterior distributions and estimate $Pr(\theta_1 &lt; \theta_2|\text{ the data and prior })$.</span></span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prior: </span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\theta \sim beta(1,1)$</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Model: </span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$p(\sum Y =n | \theta) = {N \choose n}\theta^{n}(1-\theta)^{N-n}$</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Posterior distribution <span class="co">[</span><span class="ot">@hoff2009first, pp. 37</span><span class="co">]</span>: </span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\theta | \sum_{i=1}^{N} Y_i=n \sim Beta(beta(1+n, 1+N-n))$</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>$\theta_1 \sim Beta(1+57, 1+100-57) = Beta(58, 44)$</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>$\theta_2 \sim Beta(1+30, 1+50-30) = Beta(31, 21)$  </span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>t1s <span class="op">=</span> st.beta.rvs(<span class="dv">58</span>, <span class="dv">44</span>, size<span class="op">=</span>N)</span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>t2s <span class="op">=</span> st.beta.rvs(<span class="dv">31</span>, <span class="dv">21</span>, size<span class="op">=</span>N)</span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>p_t2bigger <span class="op">=</span> np.mean(t1s <span class="op">&lt;</span> t2s) </span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Item"</span>: [<span class="st">"Pr(theta_1 &lt; theta_2 | the data and prior)"</span>],<span class="op">\</span></span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value"</span>:[p_t2bigger]})</span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a><span class="fu">## Problem 4.2</span></span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Tumor count comparisons: Reconsider the tumor count data in </span><span class="co">[</span><span class="ot">Exercise 3.3</span><span class="co">](hw2.pdf#sec-p-3-3)</span><span class="at">:</span></span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a><span class="fu">### (a)</span></span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; For the prior distribution given in part (a) of that exercise, obtain $Pr(\theta_B &lt; \theta_A | y_A, y_B)$ via Monte Carlo sampling.</span></span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prior distribution</span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\theta_A|y_A \sim gamma(120+117, 10+10) = gamma(237, 20)$</span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\theta_B|y_B \sim gamma(12+113, 1+13) = gamma(125, 14)$</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a>theta_A <span class="op">=</span> st.gamma.rvs(<span class="dv">237</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">20</span>, size<span class="op">=</span>N)</span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a>theta_B <span class="op">=</span> st.gamma.rvs(<span class="dv">125</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">14</span>, size<span class="op">=</span>N)</span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> np.mean(theta_B <span class="op">&lt;</span> theta_A)</span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb20-111"><a href="#cb20-111" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Item"</span>: [<span class="st">"Pr(theta_B &lt; theta_A | y_A, y_B)"</span>],<span class="op">\</span></span>
<span id="cb20-112"><a href="#cb20-112" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value"</span>:[res]})</span>
<span id="cb20-113"><a href="#cb20-113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-114"><a href="#cb20-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-115"><a href="#cb20-115" aria-hidden="true" tabindex="-1"></a><span class="fu">### (b)</span></span>
<span id="cb20-116"><a href="#cb20-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-117"><a href="#cb20-117" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; For a range of values of $n_0$, obtain $Pr(\theta_B &lt; \theta_A |y_A, y_B)$ for $\theta_A \sim gamma(120,10)$ and $\theta_B \sim gamma(12\times n_0, n_0)$. Describe how sensitive the conclusions about the event $</span><span class="sc">\{</span><span class="at">\theta_B &lt; \theta_A</span><span class="sc">\}</span><span class="at">$ are to the prior distribution on $\theta_B$.</span></span>
<span id="cb20-118"><a href="#cb20-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-119"><a href="#cb20-119" aria-hidden="true" tabindex="-1"></a>In @fig-42-n0, the $n_0$ decreases the probability of $p(<span class="sc">\{</span>\theta_B &lt; \theta_A<span class="sc">\}</span>)$ with linear effect. From small to large $n_0$, the prior distribution of $\theta_B$ keep influences the result.</span>
<span id="cb20-120"><a href="#cb20-120" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb20-121"><a href="#cb20-121" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-122"><a href="#cb20-122" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-42-n0</span></span>
<span id="cb20-123"><a href="#cb20-123" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The effect of n0</span></span>
<span id="cb20-124"><a href="#cb20-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-125"><a href="#cb20-125" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_A_bigger(n0, N<span class="op">=</span><span class="dv">5000</span>):</span>
<span id="cb20-126"><a href="#cb20-126" aria-hidden="true" tabindex="-1"></a>  theta_A <span class="op">=</span> st.gamma.rvs(<span class="dv">120</span> <span class="op">+</span> <span class="dv">117</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">10</span><span class="op">+</span><span class="dv">10</span>), size<span class="op">=</span>N)</span>
<span id="cb20-127"><a href="#cb20-127" aria-hidden="true" tabindex="-1"></a>  theta_B <span class="op">=</span> st.gamma.rvs(<span class="dv">12</span><span class="op">*</span>n0<span class="op">+</span><span class="dv">113</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(n0<span class="op">+</span><span class="dv">13</span>), size<span class="op">=</span>N)</span>
<span id="cb20-128"><a href="#cb20-128" aria-hidden="true" tabindex="-1"></a>  res <span class="op">=</span> np.mean(theta_B <span class="op">&lt;</span> theta_A)</span>
<span id="cb20-129"><a href="#cb20-129" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> res</span>
<span id="cb20-130"><a href="#cb20-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-131"><a href="#cb20-131" aria-hidden="true" tabindex="-1"></a>n0s <span class="op">=</span> np.arange(<span class="dv">1</span>,<span class="dv">50</span>, <span class="dv">1</span>)</span>
<span id="cb20-132"><a href="#cb20-132" aria-hidden="true" tabindex="-1"></a>ress <span class="op">=</span> [get_A_bigger(n0) <span class="cf">for</span> n0 <span class="kw">in</span> n0s]</span>
<span id="cb20-133"><a href="#cb20-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-134"><a href="#cb20-134" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb20-135"><a href="#cb20-135" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb20-136"><a href="#cb20-136" aria-hidden="true" tabindex="-1"></a>ax.plot(n0s, ress, <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb20-137"><a href="#cb20-137" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$n_0$"</span>)</span>
<span id="cb20-138"><a href="#cb20-138" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$p(</span><span class="ch">\\</span><span class="st">theta_B &lt; </span><span class="ch">\\</span><span class="st">theta_A | y_A, y_B, n_0)$"</span>)<span class="op">;</span></span>
<span id="cb20-139"><a href="#cb20-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-140"><a href="#cb20-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-141"><a href="#cb20-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-142"><a href="#cb20-142" aria-hidden="true" tabindex="-1"></a><span class="fu">### (c)</span></span>
<span id="cb20-143"><a href="#cb20-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-144"><a href="#cb20-144" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Repeat part (a) and (b), replacing the event $</span><span class="sc">\{</span><span class="at">\theta_B &lt; \theta_A\}$ with the event $\{\tilde{Y}_{B} &lt; \tilde{Y}_{A}\}$, where $\tilde{Y}_A$ and $\tilde{Y}_B$ are samples from the posterior predictive distribution.</span></span>
<span id="cb20-145"><a href="#cb20-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-146"><a href="#cb20-146" aria-hidden="true" tabindex="-1"></a>**Part I (a)**</span>
<span id="cb20-147"><a href="#cb20-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-148"><a href="#cb20-148" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\tilde{Y}_A \sim nbinom(a+\sum Y^{(A)}, b + n) = nbinom(120+117,10+10)= nbinom(237, 20)$</span>
<span id="cb20-149"><a href="#cb20-149" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\tilde{Y}_B \sim nbinom(a+\sum Y^{(B)}, b + n) = nbinom(12+113, 1+13) = nbinom(125, 14)$</span>
<span id="cb20-150"><a href="#cb20-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-151"><a href="#cb20-151" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Find $p(\tilde{Y}_{B} &lt; \tilde{Y}_A | y_A, y_B)$</span>
<span id="cb20-152"><a href="#cb20-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-153"><a href="#cb20-153" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use <span class="in">`scipy.stats.nbinom`</span><span class="ot">[^nbinom]</span></span>
<span id="cb20-154"><a href="#cb20-154" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$p = 1 - \frac{1}{b+n+1}$</span>
<span id="cb20-155"><a href="#cb20-155" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$n = a+\sum Y$</span>
<span id="cb20-156"><a href="#cb20-156" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$k = \tilde{Y}$</span>
<span id="cb20-157"><a href="#cb20-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-158"><a href="#cb20-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-159"><a href="#cb20-159" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-160"><a href="#cb20-160" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb20-161"><a href="#cb20-161" aria-hidden="true" tabindex="-1"></a>tilde_y_A <span class="op">=</span> st.nbinom.rvs(<span class="dv">120</span><span class="op">+</span><span class="dv">117</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">10</span><span class="op">+</span><span class="dv">10</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-162"><a href="#cb20-162" aria-hidden="true" tabindex="-1"></a>tilde_y_B <span class="op">=</span> st.nbinom.rvs(<span class="dv">12</span><span class="op">+</span><span class="dv">113</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="dv">13</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-163"><a href="#cb20-163" aria-hidden="true" tabindex="-1"></a>p2 <span class="op">=</span> np.mean(tilde_y_B <span class="op">&lt;</span> tilde_y_A)</span>
<span id="cb20-164"><a href="#cb20-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-165"><a href="#cb20-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-166"><a href="#cb20-166" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb20-167"><a href="#cb20-167" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb20-168"><a href="#cb20-168" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Item"</span>: [<span class="st">"Pr(tildeY_B &lt; tildeY_A | y_A, y_B)"</span>],<span class="op">\</span></span>
<span id="cb20-169"><a href="#cb20-169" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value"</span>:[p2]})</span>
<span id="cb20-170"><a href="#cb20-170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-171"><a href="#cb20-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-172"><a href="#cb20-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-173"><a href="#cb20-173" aria-hidden="true" tabindex="-1"></a>**Part II (b)**</span>
<span id="cb20-174"><a href="#cb20-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-175"><a href="#cb20-175" aria-hidden="true" tabindex="-1"></a>In @fig-423, the $n_0$ has nonlinear negative effect on the probability $p(<span class="sc">\{</span>\tilde{Y}_{B} &lt; \tilde{Y}_{A}<span class="sc">\}</span>)$ with the prior formation of $n_0$.</span>
<span id="cb20-176"><a href="#cb20-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-177"><a href="#cb20-177" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-178"><a href="#cb20-178" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-423</span></span>
<span id="cb20-179"><a href="#cb20-179" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The effect of n0</span></span>
<span id="cb20-180"><a href="#cb20-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-181"><a href="#cb20-181" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_A_bigger(n0, N<span class="op">=</span><span class="dv">5000</span>):</span>
<span id="cb20-182"><a href="#cb20-182" aria-hidden="true" tabindex="-1"></a>  tilde_y_A <span class="op">=</span> st.nbinom.rvs(<span class="dv">120</span><span class="op">+</span><span class="dv">117</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">10</span><span class="op">+</span><span class="dv">10</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-183"><a href="#cb20-183" aria-hidden="true" tabindex="-1"></a>  tilde_y_B <span class="op">=</span> st.nbinom.rvs(<span class="dv">12</span><span class="op">*</span>n0<span class="op">+</span><span class="dv">113</span>, <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(n0<span class="op">+</span><span class="dv">13</span><span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-184"><a href="#cb20-184" aria-hidden="true" tabindex="-1"></a>  res <span class="op">=</span> np.mean(tilde_y_B <span class="op">&lt;</span> tilde_y_A)</span>
<span id="cb20-185"><a href="#cb20-185" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> res</span>
<span id="cb20-186"><a href="#cb20-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-187"><a href="#cb20-187" aria-hidden="true" tabindex="-1"></a>n0s <span class="op">=</span> np.arange(<span class="dv">1</span>,<span class="dv">50</span>, <span class="dv">1</span>)</span>
<span id="cb20-188"><a href="#cb20-188" aria-hidden="true" tabindex="-1"></a>ress <span class="op">=</span> [get_A_bigger(n0) <span class="cf">for</span> n0 <span class="kw">in</span> n0s]</span>
<span id="cb20-189"><a href="#cb20-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-190"><a href="#cb20-190" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb20-191"><a href="#cb20-191" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb20-192"><a href="#cb20-192" aria-hidden="true" tabindex="-1"></a>ax.plot(n0s, ress, <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb20-193"><a href="#cb20-193" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$n_0$"</span>)</span>
<span id="cb20-194"><a href="#cb20-194" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$p(</span><span class="ch">\\</span><span class="st">tilde</span><span class="sc">{Y}</span><span class="st">_B &lt; </span><span class="ch">\\</span><span class="st">tilde</span><span class="sc">{Y}</span><span class="st">_A | y_A, y_B, n_0)$"</span>)<span class="op">;</span></span>
<span id="cb20-195"><a href="#cb20-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-196"><a href="#cb20-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-197"><a href="#cb20-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-198"><a href="#cb20-198" aria-hidden="true" tabindex="-1"></a><span class="ot">[^nbinom]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.nbinom.html#scipy.stats.nbinom</span></span>
<span id="cb20-199"><a href="#cb20-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-200"><a href="#cb20-200" aria-hidden="true" tabindex="-1"></a><span class="fu">## Problem 4.6</span></span>
<span id="cb20-201"><a href="#cb20-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-202"><a href="#cb20-202" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Non-informative prior distributions: Suppose for a binary sampling problem we plan on using a uniform, or $beta(1,1)$, prior for the population proportion $\theta$. Perhaps our reasoning is that this represents “no prior information about $\theta$.” However, some people like to look at proportions on the log-odds scale, that is, they are interested in $\gamma = \log\frac{\theta}{1−\theta}$. Via Monte Carlo sampling or otherwise, find the prior distribution for $\gamma$ that is induced by the uniform prior for $\theta$. Is the prior informative about $\gamma$?</span></span>
<span id="cb20-203"><a href="#cb20-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-204"><a href="#cb20-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-205"><a href="#cb20-205" aria-hidden="true" tabindex="-1"></a>**Part I: Analytical Approach**</span>
<span id="cb20-206"><a href="#cb20-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-207"><a href="#cb20-207" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\gamma = g(\theta) = \log\frac{\theta}{1-\theta}$</span>
<span id="cb20-208"><a href="#cb20-208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\theta = g^{-1}(\gamma) = \frac{e^{\gamma}}{1+e^{\gamma}}$</span>
<span id="cb20-209"><a href="#cb20-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-210"><a href="#cb20-210" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb20-211"><a href="#cb20-211" aria-hidden="true" tabindex="-1"></a>p_{\gamma}(\gamma) </span>
<span id="cb20-212"><a href="#cb20-212" aria-hidden="true" tabindex="-1"></a>&amp;= \underbrace{p_{\theta}(g^{-1}(\gamma))}_{=1 \because \theta\sim uniform(0,1)} \times \left|\frac{dg^{-1}(\gamma)}{d\gamma}\right|<span class="sc">\\</span> </span>
<span id="cb20-213"><a href="#cb20-213" aria-hidden="true" tabindex="-1"></a>&amp;= \left|\frac{e^{\gamma}}{(1+e^{\gamma})^2}\right|</span>
<span id="cb20-214"><a href="#cb20-214" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb20-215"><a href="#cb20-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-216"><a href="#cb20-216" aria-hidden="true" tabindex="-1"></a>**Part II: Monte Carlo Approach**</span>
<span id="cb20-217"><a href="#cb20-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-218"><a href="#cb20-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-219"><a href="#cb20-219" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-220"><a href="#cb20-220" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> true_gamma_pdf(y):</span>
<span id="cb20-221"><a href="#cb20-221" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.absolute(np.exp(y)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(y))<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb20-222"><a href="#cb20-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-223"><a href="#cb20-223" aria-hidden="true" tabindex="-1"></a>ths <span class="op">=</span> st.beta.rvs(<span class="dv">1</span>,<span class="dv">1</span>,size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb20-224"><a href="#cb20-224" aria-hidden="true" tabindex="-1"></a>gammas <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">100</span>)</span>
<span id="cb20-225"><a href="#cb20-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-226"><a href="#cb20-226" aria-hidden="true" tabindex="-1"></a>ys_true <span class="op">=</span> [true_gamma_pdf(g) <span class="cf">for</span> g <span class="kw">in</span> gammas]</span>
<span id="cb20-227"><a href="#cb20-227" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> [np.log(th<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>th)) <span class="cf">for</span> th <span class="kw">in</span> ths]</span>
<span id="cb20-228"><a href="#cb20-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-229"><a href="#cb20-229" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()<span class="op">;</span></span>
<span id="cb20-230"><a href="#cb20-230" aria-hidden="true" tabindex="-1"></a>ax.hist(ys, weights<span class="op">=</span>np.ones_like(ys)<span class="op">/</span><span class="bu">len</span>(ys))<span class="op">;</span></span>
<span id="cb20-231"><a href="#cb20-231" aria-hidden="true" tabindex="-1"></a>ax.plot(gammas, ys_true, label<span class="op">=</span><span class="st">"Analytical solution"</span>)<span class="op">;</span></span>
<span id="cb20-232"><a href="#cb20-232" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">gamma=</span><span class="ch">\\</span><span class="st">log</span><span class="ch">\\</span><span class="st">frac{</span><span class="ch">\\</span><span class="st">theta}{1-</span><span class="ch">\\</span><span class="st">theta}$"</span>)</span>
<span id="cb20-233"><a href="#cb20-233" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$p(</span><span class="ch">\\</span><span class="st">gamma)$"</span>)</span>
<span id="cb20-234"><a href="#cb20-234" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span>
<span id="cb20-235"><a href="#cb20-235" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-236"><a href="#cb20-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-237"><a href="#cb20-237" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The prior of $\gamma$ is informative since it is centered around the $0$.</span>
<span id="cb20-238"><a href="#cb20-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-239"><a href="#cb20-239" aria-hidden="true" tabindex="-1"></a><span class="fu">## Problem 4.8 {#sec-p48}</span></span>
<span id="cb20-240"><a href="#cb20-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-241"><a href="#cb20-241" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; More posterior predictive checks: Let $\theta_A$ and $\theta_B$ be the average number of children of men in their 30s with and without bachelor's degrees, respectively.</span></span>
<span id="cb20-242"><a href="#cb20-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-243"><a href="#cb20-243" aria-hidden="true" tabindex="-1"></a><span class="fu">### (a)</span></span>
<span id="cb20-244"><a href="#cb20-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-245"><a href="#cb20-245" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Using a Poisson sampling model, a $gamma(2,1)$ prior for each $\theta$ and the data in the files </span><span class="co">[</span><span class="ot">`menchild30bach.dat`</span><span class="co">](data/menchild30bach.dat.txt)</span><span class="at"> and </span><span class="co">[</span><span class="ot">`menchild30nobach.dat`</span><span class="co">](data/menchild30nobach.dat.txt)</span><span class="at">, obtain $5000$ samples of $\bar{Y}_{A}$ and $\bar{Y}_{B}$ from the posterior predictive distribution of the two samples. Plot the Monte Carlo approximations to these two posterior predictive distributions. (data available in </span><span class="co">[</span><span class="ot">Appendix</span><span class="co">](#sec-data)</span><span class="at">)</span></span>
<span id="cb20-246"><a href="#cb20-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-247"><a href="#cb20-247" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-248"><a href="#cb20-248" aria-hidden="true" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb20-249"><a href="#cb20-249" aria-hidden="true" tabindex="-1"></a>dataA <span class="op">=</span> np.loadtxt(<span class="st">"data/menchild30bach.dat"</span>)</span>
<span id="cb20-250"><a href="#cb20-250" aria-hidden="true" tabindex="-1"></a>dataB <span class="op">=</span> np.loadtxt(<span class="st">"data/menchild30nobach.dat"</span>)</span>
<span id="cb20-251"><a href="#cb20-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-252"><a href="#cb20-252" aria-hidden="true" tabindex="-1"></a><span class="co"># Display </span></span>
<span id="cb20-253"><a href="#cb20-253" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb20-254"><a href="#cb20-254" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Properties"</span>: [<span class="st">"Sum"</span>, <span class="st">"N (number of samples)"</span>],</span>
<span id="cb20-255"><a href="#cb20-255" aria-hidden="true" tabindex="-1"></a>  <span class="st">"A"</span>: [np.<span class="bu">sum</span>(dataA), <span class="bu">len</span>(dataA)],</span>
<span id="cb20-256"><a href="#cb20-256" aria-hidden="true" tabindex="-1"></a>  <span class="st">"B"</span>: [np.<span class="bu">sum</span>(dataB), <span class="bu">len</span>(dataB)]</span>
<span id="cb20-257"><a href="#cb20-257" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb20-258"><a href="#cb20-258" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-259"><a href="#cb20-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-260"><a href="#cb20-260" aria-hidden="true" tabindex="-1"></a>The predictive distribution is</span>
<span id="cb20-261"><a href="#cb20-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-262"><a href="#cb20-262" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\bar{Y_A} | y_A \sim nbinom(2+54,1+58)$</span>
<span id="cb20-263"><a href="#cb20-263" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\bar{Y_B} | y_B \sim nbinom(2+305, 1+218)$</span>
<span id="cb20-264"><a href="#cb20-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-265"><a href="#cb20-265" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-266"><a href="#cb20-266" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb20-267"><a href="#cb20-267" aria-hidden="true" tabindex="-1"></a>bar_ya <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span> np.<span class="bu">sum</span>(dataA), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataA)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-268"><a href="#cb20-268" aria-hidden="true" tabindex="-1"></a>bar_yb <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span> np.<span class="bu">sum</span>(dataB), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataB)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-269"><a href="#cb20-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-270"><a href="#cb20-270" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb20-271"><a href="#cb20-271" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()<span class="op">;</span></span>
<span id="cb20-272"><a href="#cb20-272" aria-hidden="true" tabindex="-1"></a>[ax.hist(ys, weights<span class="op">=</span>np.ones_like(ys)<span class="op">/</span><span class="bu">len</span>(ys), label<span class="op">=</span>n, alpha<span class="op">=</span><span class="fl">0.7</span>, bins<span class="op">=</span>np.arange(<span class="dv">0</span>,<span class="dv">8</span>,<span class="dv">1</span>)) <span class="cf">for</span> n,ys <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">"A"</span>,<span class="st">"B"</span>],[bar_ya, bar_yb])]</span>
<span id="cb20-273"><a href="#cb20-273" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$N$"</span>)</span>
<span id="cb20-274"><a href="#cb20-274" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Probability"</span>)</span>
<span id="cb20-275"><a href="#cb20-275" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span>
<span id="cb20-276"><a href="#cb20-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-277"><a href="#cb20-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-278"><a href="#cb20-278" aria-hidden="true" tabindex="-1"></a><span class="fu">### (b)</span></span>
<span id="cb20-279"><a href="#cb20-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-280"><a href="#cb20-280" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Find $95\%$ quantile-based posterior confidence intervals for $\theta_B - \theta_A$ and $\tilde{Y}_B-\tilde{Y}_A$. Describe in words the differences between the two populations using these quantities and the plots in (a), along with any other results that may of interest to you.</span></span>
<span id="cb20-281"><a href="#cb20-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-282"><a href="#cb20-282" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\theta_A | y_A \sim gamma(2+54, 1+58)$</span>
<span id="cb20-283"><a href="#cb20-283" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\theta_B | y_B \sim gamma(2+58, 1+218)$</span>
<span id="cb20-284"><a href="#cb20-284" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\bar{Y_A} | y_A \sim nbinom(2+54,1+58)$</span>
<span id="cb20-285"><a href="#cb20-285" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\bar{Y_B} | y_B \sim nbinom(2+305, 1+218)$</span>
<span id="cb20-286"><a href="#cb20-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-287"><a href="#cb20-287" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The $95\%$ confidence interval does not contain the negative region. Thus, the belief of $\theta_B &gt; \theta_A$ is confident.</span>
<span id="cb20-288"><a href="#cb20-288" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>However, there is more uncertainty about the posterior predictive distribution, leading to the uncertain quantity comparison between $Y_A$ and $Y_B$.</span>
<span id="cb20-289"><a href="#cb20-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-290"><a href="#cb20-290" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-291"><a href="#cb20-291" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb20-292"><a href="#cb20-292" aria-hidden="true" tabindex="-1"></a>thetaAs <span class="op">=</span> st.gamma.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataA), scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataA)), size<span class="op">=</span>N)</span>
<span id="cb20-293"><a href="#cb20-293" aria-hidden="true" tabindex="-1"></a>thetaBs <span class="op">=</span> st.gamma.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataB), scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataB)), size<span class="op">=</span>N)</span>
<span id="cb20-294"><a href="#cb20-294" aria-hidden="true" tabindex="-1"></a>YAs <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataA), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataA)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-295"><a href="#cb20-295" aria-hidden="true" tabindex="-1"></a>YBs <span class="op">=</span> st.nbinom.rvs(<span class="dv">2</span><span class="op">+</span>np.<span class="bu">sum</span>(dataB), <span class="dv">1</span> <span class="op">-</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(dataB)<span class="op">+</span><span class="dv">1</span>), size<span class="op">=</span>N)</span>
<span id="cb20-296"><a href="#cb20-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-297"><a href="#cb20-297" aria-hidden="true" tabindex="-1"></a>theta_diff <span class="op">=</span> thetaBs <span class="op">-</span> thetaAs</span>
<span id="cb20-298"><a href="#cb20-298" aria-hidden="true" tabindex="-1"></a>Y_diff <span class="op">=</span> YBs <span class="op">-</span> YAs</span>
<span id="cb20-299"><a href="#cb20-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-300"><a href="#cb20-300" aria-hidden="true" tabindex="-1"></a>theta_quan <span class="op">=</span> st.mstats.mquantiles(theta_diff, prob<span class="op">=</span>[<span class="fl">0.025</span>, <span class="fl">0.975</span>])</span>
<span id="cb20-301"><a href="#cb20-301" aria-hidden="true" tabindex="-1"></a>Y_quan <span class="op">=</span> st.mstats.mquantiles(Y_diff, prob<span class="op">=</span>[<span class="fl">0.025</span>, <span class="fl">0.975</span>])</span>
<span id="cb20-302"><a href="#cb20-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-303"><a href="#cb20-303" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb20-304"><a href="#cb20-304" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"RVs"</span>:[<span class="st">"Interval (thetaB-thetaA)"</span>, <span class="st">"Interval (YB-YA)"</span>],<span class="op">\</span></span>
<span id="cb20-305"><a href="#cb20-305" aria-hidden="true" tabindex="-1"></a>              <span class="st">"Value (2.5%; 97.5%)"</span>:[theta_quan, Y_quan]})</span>
<span id="cb20-306"><a href="#cb20-306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-307"><a href="#cb20-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-308"><a href="#cb20-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-309"><a href="#cb20-309" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-310"><a href="#cb20-310" aria-hidden="true" tabindex="-1"></a>plt.hist(theta_diff, weights<span class="op">=</span>np.ones_like(theta_diff)<span class="op">/</span><span class="bu">len</span>(theta_diff), alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb20-311"><a href="#cb20-311" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribution of ThetaB - ThetaA"</span>)</span>
<span id="cb20-312"><a href="#cb20-312" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span>
<span id="cb20-313"><a href="#cb20-313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-314"><a href="#cb20-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-315"><a href="#cb20-315" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-316"><a href="#cb20-316" aria-hidden="true" tabindex="-1"></a>plt.hist(Y_diff, weights<span class="op">=</span>np.ones_like(Y_diff)<span class="op">/</span><span class="bu">len</span>(Y_diff), alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb20-317"><a href="#cb20-317" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribution of YB - YA"</span>)</span>
<span id="cb20-318"><a href="#cb20-318" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span>
<span id="cb20-319"><a href="#cb20-319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-320"><a href="#cb20-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-321"><a href="#cb20-321" aria-hidden="true" tabindex="-1"></a><span class="fu">### (c)</span></span>
<span id="cb20-322"><a href="#cb20-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-323"><a href="#cb20-323" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Obtain the empirical distribution of the data in group $B$. Compare this to the Poisson distribution with mean $\hat{\theta}=1.4$. Do you think the Poisson model is a good fit? Why or Why not?</span></span>
<span id="cb20-324"><a href="#cb20-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-325"><a href="#cb20-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-326"><a href="#cb20-326" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\bar{Y}_B | y_B \sim nbinom(307, 219)$</span>
<span id="cb20-327"><a href="#cb20-327" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The poisson model is not a good fit to the group $B$. As shown in the historgram, there are more than one peak in the distribution, that is not the characteristic of Poisson distribution.</span>
<span id="cb20-328"><a href="#cb20-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-329"><a href="#cb20-329" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-330"><a href="#cb20-330" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.arange(<span class="dv">0</span>,<span class="dv">7</span>,<span class="dv">1</span>)</span>
<span id="cb20-331"><a href="#cb20-331" aria-hidden="true" tabindex="-1"></a>ps <span class="op">=</span> [st.poisson.pmf(x, <span class="fl">1.4</span>) <span class="cf">for</span> x <span class="kw">in</span> xs]</span>
<span id="cb20-332"><a href="#cb20-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-333"><a href="#cb20-333" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb20-334"><a href="#cb20-334" aria-hidden="true" tabindex="-1"></a>ax.hist(dataB, weights<span class="op">=</span>np.ones_like(dataB)<span class="op">/</span><span class="bu">len</span>(dataB), alpha<span class="op">=</span><span class="fl">0.7</span>)<span class="op">;</span></span>
<span id="cb20-335"><a href="#cb20-335" aria-hidden="true" tabindex="-1"></a>ax.plot(xs, ps, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Poisson($</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">theta}$=1.4)"</span>)</span>
<span id="cb20-336"><a href="#cb20-336" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span>
<span id="cb20-337"><a href="#cb20-337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-338"><a href="#cb20-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-339"><a href="#cb20-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-340"><a href="#cb20-340" aria-hidden="true" tabindex="-1"></a><span class="fu">### (d)</span></span>
<span id="cb20-341"><a href="#cb20-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-342"><a href="#cb20-342" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; For each of the $5000$ $\theta_B$-valeus you sampled, sample $n_B=218$ Poisson random variables and count the number of $0$s and the number of $1$s in each of the $5000$ simulated datasets. You should now have tow sequences of length $5000$ each, one sequence counting the number of people having zero children for each of the $5000$ posterior predictive datasets, the other counting the number of people with one child. Plot the two sequences against one another (one on the $x$-axis, one on the $y$-axis). Add to the plot a point marking how many people in the observed dataset had zero children and one child. Using this plot, describe the adequency of the Poisson model.</span></span>
<span id="cb20-343"><a href="#cb20-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-344"><a href="#cb20-344" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-345"><a href="#cb20-345" aria-hidden="true" tabindex="-1"></a>thetaBs <span class="op">=</span> thetaBs</span>
<span id="cb20-346"><a href="#cb20-346" aria-hidden="true" tabindex="-1"></a>nB <span class="op">=</span> <span class="dv">218</span></span>
<span id="cb20-347"><a href="#cb20-347" aria-hidden="true" tabindex="-1"></a>ybs0 <span class="op">=</span> np.zeros(<span class="bu">len</span>(thetaBs))</span>
<span id="cb20-348"><a href="#cb20-348" aria-hidden="true" tabindex="-1"></a>ybs1 <span class="op">=</span> np.zeros(<span class="bu">len</span>(thetaBs))</span>
<span id="cb20-349"><a href="#cb20-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-350"><a href="#cb20-350" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i, th) <span class="kw">in</span> <span class="bu">enumerate</span>(thetaBs):</span>
<span id="cb20-351"><a href="#cb20-351" aria-hidden="true" tabindex="-1"></a>  seq <span class="op">=</span> st.poisson.rvs(th, size<span class="op">=</span>nB)</span>
<span id="cb20-352"><a href="#cb20-352" aria-hidden="true" tabindex="-1"></a>  ybs0[i] <span class="op">=</span> <span class="bu">len</span>(seq[seq<span class="op">==</span><span class="dv">0</span>])</span>
<span id="cb20-353"><a href="#cb20-353" aria-hidden="true" tabindex="-1"></a>  ybs1[i] <span class="op">=</span> <span class="bu">len</span>(seq[seq<span class="op">==</span><span class="dv">1</span>])</span>
<span id="cb20-354"><a href="#cb20-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-355"><a href="#cb20-355" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb20-356"><a href="#cb20-356" aria-hidden="true" tabindex="-1"></a>ax.plot(ybs0, ybs1, <span class="st">"o"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb20-357"><a href="#cb20-357" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">len</span>(dataB[dataB<span class="op">==</span><span class="dv">0</span>]), <span class="bu">len</span>(dataB[dataB<span class="op">==</span><span class="dv">1</span>]), <span class="st">'o'</span>,color<span class="op">=</span><span class="st">"r"</span>)</span>
<span id="cb20-358"><a href="#cb20-358" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"N of people with zero children"</span>)</span>
<span id="cb20-359"><a href="#cb20-359" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"N of people with one children"</span>)</span>
<span id="cb20-360"><a href="#cb20-360" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-361"><a href="#cb20-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-362"><a href="#cb20-362" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The observed data is in red, but the simulated data is centralized far from that point. Thus, the poisson model is not appropriate for this dataset.</span>
<span id="cb20-363"><a href="#cb20-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-364"><a href="#cb20-364" aria-hidden="true" tabindex="-1"></a><span class="fu">## Appendix</span></span>
<span id="cb20-365"><a href="#cb20-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-366"><a href="#cb20-366" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data set in [Problem 4.8](#sec-p48) {#sec-data}</span></span>
<span id="cb20-367"><a href="#cb20-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-368"><a href="#cb20-368" aria-hidden="true" tabindex="-1"></a><span class="in">``` {python}</span></span>
<span id="cb20-369"><a href="#cb20-369" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"menchild30bach.dat:</span><span class="ch">\n</span><span class="st">"</span>, dataA)</span>
<span id="cb20-370"><a href="#cb20-370" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"menchild30nobach.dat:</span><span class="ch">\n</span><span class="st">"</span>, dataB)</span>
<span id="cb20-371"><a href="#cb20-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-372"><a href="#cb20-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-373"><a href="#cb20-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-374"><a href="#cb20-374" aria-hidden="true" tabindex="-1"></a>::: {.content-hidden when-format="html"}</span>
<span id="cb20-375"><a href="#cb20-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-376"><a href="#cb20-376" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb20-377"><a href="#cb20-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-378"><a href="#cb20-378" aria-hidden="true" tabindex="-1"></a>:::</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>